---
layout: about
title: about
permalink: /

profile:
  align: right
  image: profile_columbia_totleneck.JPG # original prof_pic.jpg. May still persist in different locations.
  image_circular: false # crops the image to make it circular
  # more_info: >
  #  <p>555 your office number</p>
  #  <p>123 your address street</p>
  #  <p>Your City, State 12345</p>

news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

Hi! I am Zhonghao, a master's student at the University of Cambridge. I do AI alignment, interpretability, human-AI interaction, and machine ethics research, with a focus on creating AI-assistants for human moral & cultural progress and preventing LLM-induced lock-in. I will be graduating in 2025 and I am seeking PhD positions!

## Research

You may read my published work on [Google Scholar](https://scholar.google.com/citations?user=PuUcZTYAAAAJ&hl=en&oi=ao). My ongoing and past projects are more updated in the [CV](https://hezhonghao.github.io/cv/) page of this site.

My current "[Hamming Problems](https://www.cs.virginia.edu/~robins/YouAndYourResearch.html)" (the most important problems I can work on) are:

- Will we be experiencing an LLM-induced value lock-in? If so, how do we prevent it from happenning ([Two Papers Under Review](https://docs.google.com/document/d/19HxnSQtftkFguxnlbUk2h4-BTgXdt02hHXJFnSyCIUA/edit?tab=t.0#heading=h.obviu1nlvltd))
- Can we train LLM to uplift humans by using truth-seeking as underlying objective, opinion-change data as ground truth for RLHF, and explictly evaluting AI-assisted human performance ([An Algorithmic Paper Aiming For NeurIPS 2025](https://docs.google.com/document/d/1rHhOVqLlEMwZYJ7p520P9Qctjj52LlU0y6tza32xENo/edit?tab=t.0#bookmark=id.5fxoxdo65tzy))?

I strive to become a "full stack researcher," which, in my definition, is to have technical sophistication (experiments, mathematical formulation, and engineering) and deep engagements with problems (technical and societal ones). Building technologies for human betterment is hard, and let's get this one right.

Ultimately, I want to build AIs for human excellence (or "arete", in Greek conception), which requires both sound societal mechanism design and epistemic tools with which individuals can better exercise their agency.

A lot of effort is required to operationalize those concepts, but currently I am actively exploring the following topics: mechanistic interpretability, computational neuroscience, AI ethics, alignment, political philosophy, virtue ethics, multi-agent systems, AI for science, and human-computer interface, and collective intelligence.

## Contacts

You may simply book a quick call via [Calendly](https://calendly.com/hezhonghao). You may drop me an email at hezhonghao2030@gmail.com
