{
  "basics": {
    "name": "Zhonghao He (何忠豪)",
    "label": "AI Alignment and Human-AI Interaction Researcher",
    "image": "",
    "Affiliation": "Leverhulme Center for Future Intelligence, University of Cambridge",
    "summary": "I am creating AI-assistants for human moral progress and preventing LLM-induced lock-in. My work is the only necessary form of my existence. I build, therefore I exist."
  },
  "education": [
    {
      "institution": "University of Cambridge",
      "location": "Cambridge, UK",
      "url": "https://www.lcfi.ac.uk/",
      "area": "AI Ethics and Society",
      "studyType": "Master",
      "startDate": "2022-09-01",
      "endDate": "PRESENT",
      "Advisors": "Henry Shevlin",
      "courses": [
        "Machine Learning Alignment",
        "AI Ethics",
        "AI Governance",
        "CS230 Deep Learning",
        "ML Safety",
        "Discrete Mathematics",
        "CS234 Reinforcement Learning",
        "CS109 Probability for Computer Scientists",
        "Mechanistic Interpretability",
        "Algorithms and Data Structure"
      ]
    },
    {
      "institution": "Stanford University",
      "location": "Palo Alto, USA",
      "url": "https://www.stanford.edu/",
      "area": "Cognitive Science & Philosophy",
      "studyType": "Summer Student",
      "startDate": "2019-06-01",
      "endDate": "2019-09-01",
      "courses": ["Mathematics Foundation of Computing", "Minds and Machines", "Introduction to Neuroscience"]
    },
    {
      "institution": "Shantou University",
      "location": "Shantou, China",
      "url": "https://www.stu.edu.cn/",
      "area": "English & Global Studies",
      "studyType": "Bachelor of Arts",
      "startDate": "2014-08-01",
      "endDate": "2019-06-01",
      "honors": ["Stanford Global Leadership & Engagement Program Scholarship", "Hong Kong Cyberport Creative Micro Funding $100,000"],
      "courses": ["Machine Learning and relevant maths", "Research Methodology", "Linguistics"]
    }
  ],
  "projects": [
    {
      "startDate": "2025-03",
      "endDate": "Present",
      "name": "Stay True to the Evidence:Measuring Belief Entrenchment in LLM Reasoning via the Martingale Score",
      "url": "https://drive.google.com/file/d/1Wl25FB88BeyRpU470IBU3e606i-ZlLYC/view?usp=sharing",
      "summary": "We propose an alternative to RLHF that uses \" helping humans to seek truth as training objective \" and human opinion change data as ground truth. By doing so we aim to remove feedback loop-incurred lock-in from its root and revolves alignment evaluation around \" LLM-assited human performanceWe \".",
      "highlights": [
        "Position: Project Co-founder",
        "Collaborators: Prof Maarten Sap (CMU), Prof Hirokazu Shirado, Tianyi (Alex) Qiu (CHAI, Berkley & PKU"
      ]
    },
    {
      "startDate": "2024-10",
      "endDate": "2025-05",
      "name": "The Lock-in Hypothesis: Stagnation by Algorithms",
      "url": "https://openreview.net/pdf?id=4CRMWP1tYc",
      "summary": "We are concerned with the problems of LLM-incured value lock-in and knowledge collapse (as probable as model collapse since increasingly our discourses are mediated by AI systems and iterative training becomes more prevalence), with the consequence being more destructive. Our team establishes real-world evdience of lock-in from WildChat data and builds simulations and formal modeling of the mechanisms of LLM-incurred value lock-in",
      "highlights": ["Position: Project Co-founder", "Collaborators: Prof Max Kleiman-Weiner (UW), Tianyi (Alex) Qiu (CHAI, Berkley & PKU"]
    },
    {
      "startDate": "2024-10",
      "endDate": "2025-01",
      "name": "Open Problems in AI Influence",
      "url": "https://docs.google.com/document/d/1HQE_MQZzHXWf04xmn0N38DQZXu3nUZaufqpGGDx_LJQ/edit?usp=sharing",
      "summary": "We propose \"AI influence \" as a field of studies on AI's impact on epistemics and morality. In this paper we collect open problems in AI influence, as long as methodologies from ML, computational social science, cognitive science to study AI influence.",
      "highlights": [
        "Position: Project Co-founder",
        "Collaborators: Prof Max Kleiman-Weiner (UW), Tianyi (Alex) Qiu (CHAI, Berkley & PKU, Prof Atoosa Kasirzadeh, Prof John P Wihbey, Dr Moshe Glickman, Tao Lin."
      ]
    },
    {
      "startDate": "2025-5",
      "endDate": "2025-6",
      "name": "Position: AI Presents Catastrophic Epistemic Risks",
      "url": "https://docs.google.com/document/d/1gczIOi5tG-6x6HKMtShd7eUAW6Znh7fbKvI9n1oCt6M/edit?usp=sharing",
      "summary": "We argue that AI presents catastrophic epistemic risks, which deserves a closer look and more research attention to.",
      "highlights": ["Position: Co-author", "Collaborators: Kellin Pelrine, Dan Zhao, Tianyi (Alex) Qiu"]
    },
    {
      "startDate": "2023-12",
      "endDate": "2025-02",
      "name": "Multilevel analytical framework for interpretability",
      "url": "https://arxiv.org/abs/2408.12664v2",
      "summary": "Research on cognitive science and neuroscience to address interpretability challenges in ML.",
      "highlights": [
        "Position: Project Lead",
        "Goal: Publication in Transactional Machine Learning Research",
        "Senior authors: Grace W. Lindsay(NYU), Prof Anna Ivanova (GeorgiaTech)"
      ]
    },
    {
      "startDate": "2023-07",
      "endDate": "2023-10",
      "name": "Comprehensive Survey on AI Alignment",
      "url": "https://alignmentsurvey.com/",
      "summary": "Survey paper on alignment research for newcomers.",
      "highlights": ["Focus: Interpretability challenges in ML", "Collaborators: Yaodong Yang, Jiaming Ji, Tianyi Qiu"]
    },
    {
      "startDate": "2022-12",
      "endDate": "2023-03",
      "name": "Harms from agentic algorithmic systems",
      "url": "https://arxiv.org/abs/2302.10329",
      "summary": "Research on safety and harms from agentic systems in AI.",
      "highlights": ["Highlight: Published paper cited by GPT-4 and high-profile AI safety reports"]
    },
    {
      "startDate": "2021-06",
      "endDate": "2022-02",
      "name": "Stanford Existential Risks Initiative (SERI)",
      "url": "https://seri.stanford.edu/resources/courses/seri-fellowship/summer-2021-undergraduate-research-fellowship-featured-projects",
      "summary": "Research on China's AI governance approach.",
      "highlights": ["Position: Research Fellow"]
    }
  ],
  "awards": [
    {
      "date": "2022-08",
      "title": "Open Philanthropy Graduate Scholarship",
      "awarder": "Open Philanthropy",
      "summary": "A full scholarship for the master of study in AI Ethics and Society at the University of Cambridge."
    },
    {
      "date": "2023-01",
      "title": "Manifund AI Research Scholarship",
      "url": "https://manifund.org/projects/mapping-neuroscience-and-mechanistic-interpretability-?tab=donations",
      "awarder": "Manifund",
      "summary": "A research scholarship to support work on neuroscience and mechanistic interpretability."
    },
    {
      "date": "2017-02",
      "title": "Hong Kong Cyberport Creative Micro Funding",
      "url": "https://www.cyberport.hk/files/597951a9ed60c582280509/Cyberport%20Guangdong%20%E2%80%93%20Hong%20Kong%20Young%20Entrepreneur%20Programme%202016%20result_EN_v2.pdf",
      "awarder": "Hong Kong Cyberport Management Company Limited, wholly owned by the Hong Kong SAR Government",
      "summary": "Early-stage startup funding to support work on Homeal, a sharing economy app about food and culture."
    }
  ],
  "skills": [
    {
      "name": "Mathematics",
      "keywords": ["Calculus", "Information Theory", "Linear Algebra", "Formal Methods"]
    },
    {
      "name": "ML Engineering",
      "keywords": ["Machine Learning", "Deep Learning", "Data Analysis", "ML Safety", "Git"]
    },
    {
      "name": "Experimental",
      "keywords": ["Data Visualization", "Mechanistic Interpretability", "Simulation"]
    },
    {
      "name": "Programming",
      "keywords": ["Python (advanced)", "Pytorch", "R (intermediary)", "web stuff (intermediary)", "Matlab (basic)", "C/C++ (basic)"]
    }
  ],
  "languages": [
    {
      "language": "English",
      "fluency": "Close to Native",
      "icon": ""
    },
    {
      "language": "Chinese",
      "fluency": "Native",
      "icon": ""
    },
    {
      "language": "French",
      "fluency": "Basic",
      "icon": ""
    }
  ],
  "interests": [
    {
      "name": "Physical Activities",
      "keywords": ["Rowing", "Hiking"]
    },
    {
      "name": "Other Interests",
      "keywords": ["Debate", "Greek Literature"]
    }
  ]
}
