<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Your Name</title>
    <style>
        body {
            font-family: Georgia, serif;
            line-height: 1.6;
            max-width: 700px;
            margin: 60px auto;
            padding: 0 20px;
            color: #333;
        }
        
        h1 {
            font-size: 1.8em;
            margin-bottom: 0.3em;
            font-weight: normal;
        }
        
        h2 {
            font-size: 1.3em;
            margin-top: 2em;
            margin-bottom: 0.5em;
            font-weight: normal;
        }
        
        h3 {
            font-size: 1.1em;
            margin-top: 1.5em;
            margin-bottom: 0.5em;
            font-weight: normal;
        }
        
        a {
            color: #0066cc;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        p {
            margin: 1em 0;
        }
        
        ul {
            margin: 1em 0;
            padding-left: 2em;
        }
        
        li {
            margin: 0.5em 0;
        }
        
        strong {
            font-weight: 600;
        }
        
        em {
            font-style: italic;
        }
    </style>
</head>
<body>
    <h1>Zhonghao He (何忠豪)</h1>
    
    <p>
        Hi! I am Zhonghao (何忠豪), a master's student at the University of Cambridge and an incoming intern at FLAIR, Oxford. My research focuses on truth-seeking AI and moral progress.
    </p>
    
    <p>
        My previous work got accepted by NeurIPS, ICML, ACM FAccT, and ICLR (workshop), etc. My major interests are to design machines that help humans learn, think, and deliberate. Currently I work on two things, to develop truth-seeking AI (Bayesian & truth-seeking in open-ended domains), and to solve "positive feedback loop" problems in tech products (LLM sycophancy, social media echo chamber, and polarization).
    </p>
    
    <p>
        I am serving as a mentor at the Supervised Program for Alignment Research and the Algoverse AI Safety Fellowship. Read our <a href="https://tinyurl.com/prevailai">research updates</a> and <a href="https://docs.google.com/document/d/17HGZ8M8QY5Lvna3Cxp83U6uXNMbnWRJWA1t3dE6yoco/edit?tab=t.0">idea portal</a> if you would like to informally work with me.
    </p>
    
    <p>
        I am graduating in this year and I will be seeking research & PhD positions!
    </p>
    
    <h2>Research</h2>
    
    <p>
        You may read my published work on <a href="https://scholar.google.com/citations?user=PuUcZTYAAAAJ&hl=en&oi=ao">Google Scholar</a>. My ongoing and past projects are more updated in the CV page on this site.
    </p>
    
    <p>
        My current "<a href="https://www.cs.virginia.edu/~robins/YouAndYourResearch.html">Hamming Problems</a>" (the most important problems I can work on) are:
    </p>
    
    <ul>
        <li>Will humanity experience an LLM-induced value lock-in because of the mutual learning feedback loops between humans and LLMs? (ICML 2025; Read <a href="https://thelockinhypothesis.com">The Lock-in Hypothesis</a>)</li>
        <li>Can we train truth-seeking AI when agentic AI starts to mediate almost all our information intakes? (NeurIPS 2025; Read <a href="https://tinyurl.com/martingalescore">Martingale Score: An Unsupervised Metric for LLM Bayesian Reasoning</a>)</li>
    </ul>
    
    <p>
        I strive to become a "full stack researcher," which, in my definition, is to have technical sophistication (experiments, mathematical formulation, and engineering) and deep engagements with problems (technical and societal ones). Building technologies for human betterment is hard, and let's get this one right.
    </p>
    
    <p>
        Ultimately, I want to build AIs for human excellence (or "arete", in Greek conception) and moral progress, which requires both sound societal mechanism design and epistemic tools with which individuals can better exercise their agency.
    </p>
    
    <p>
        A lot of effort is required to operationalize those concepts, but currently I am actively exploring the following topics: mechanistic interpretability, computational neuroscience, AI ethics, alignment, political philosophy, virtue ethics, multi-agent systems, AI for science, and human-computer interface, and collective intelligence.
    </p>
    
    <h2>Gratitude</h2>
    
    <p>
        I am forever grateful to the mentorship of <a href="https://faculty.washington.edu/maxkw/">Max Kleiman-Weiner</a>, <a href="https://maartensap.com/">Maarten Sap</a>, <a href="https://www.shirado.net/">Hirokazu Shirado</a>, Henry Shevlin, <a href="https://gracewlindsay.com/">Grace W. Lindsay</a>, <a href="https://anna-ivanova.net/">Anna Ivanova</a>. They have played significant roles in supporting my academic career.
    </p>
    
    <h2>Contacts</h2>
    
    <p>
        I overall have an <a href="https://www.cs.virginia.edu/~robins/YouAndYourResearch.html#:~:text=Another%20trait%2C%20it,they%20miss%20fame.">"open-door" policy</a>, meaning that I am in general very open for people to book a slot on my calendar on Monday/Friday to discuss research/startups. <a href="https://calendly.com/hezhonghao">Calendly</a>
    </p>
</body>
</html>