---
layout: about
title: about
permalink: /

profile:
  align: right
  image: profile_columbia_totleneck.JPG
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>555 your office number</p>
    <p>123 your address street</p>
    <p>Your City, State 12345</p>

news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---
Hi! I am Zhonghao, a master's student at the University of Cambridge.

My research interests started with [interpretability](https://arxiv.org/abs/2408.12664) and [AI alignment](https://alignmentsurvey.com/). On the one hand it's about understanding the machines in front of us; on the other hand it's about effective cooperation between humans and machines.

Ultimately, I want to build AIs for human excellence (or "arete", in Greek conception), which requires both sound societal mechanism design and epistemic tools with which individuals can better exercise their agency.

A lot of effort is required to operationalize those concepts, but currently I am actively exploring the following topics: mechanistic interpretability, computational neuroscience, AI ethics, alignment, political philosophy, virtue ethics, multi-agent systems, AI for science, and human-computer interface, and collective intelligence.

## Research

You may read my published work on [Google Scholar](https://scholar.google.com/citations?user=PuUcZTYAAAAJ&hl=en&oi=ao).

My current "[Hamming Problems](https://www.cs.virginia.edu/~robins/YouAndYourResearch.html)" (the most important problems I can work on) are:

* How does knowledge diversity get lost from training and using LLM? (an ongoing [research paper aiming for ICLR](https://docs.google.com/document/d/167yB9PMSPP5yRnu4_VmWkR3zG0rXRwQApnm5YVNJZag/edit))
* How do we better understand neural networks with mechanistic interpretability, information theory, and neuroscience? ([a survey here](https://arxiv.org/abs/2408.12664))
* What knowledge assistant helps humans to think better? (exploring this topic in this [doc](https://docs.google.com/document/d/1psEHZkrWzuQMMYVnorSFO8anTczMc5o7beR7JOTIEs4/edit?usp=sharing))

I strive to become a "full stack researcher," which, in my definition, is to have technical sophistication (experiments, mathematics, and engineering) and deep engagements with problems (technical and societal ones). Building technologies for human betterment is hard, and let's get this one right.

Here is [a list of research projects](https://docs.google.com/document/d/1lICZ5ftJwZbVLm2f0NockRuwiDryhxRhHEXF4jg76dM/edit) I am interested in working on.

## Contacts

I love free-flow research conversations! You may simply book a quick call via [Calendly](calendly.com/hezhonghao). (I blocked deep work, sleep, and private time, so don't worry!). You may drop me an email at zh378@cam.ac.uk



